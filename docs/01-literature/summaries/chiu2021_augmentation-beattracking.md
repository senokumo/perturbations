---
title: Source Separation-based Data Augmentation for Improved Joint Beat and Downbeat Tracking
authors: Ching-Yu Chiu, Joann Ching, Wen-Yi Hsiao, Yu-Hua Chen, Alvin Wen-Yu Su, Yi-Hsuan Yang
year: "2021"
link:
  - https://arxiv.org/abs/2106.08703
tags:
  - augmentation
relevance: medium
---
## Abstract //todo shorten to summary!
Due to advances in deep learning, the performance of automatic beat and downbeat tracking in musical audio signals has seen great improvement in recent years. In training such deep learning based models, data augmentation has been found an important technique. However, existing data augmentation methods for this task mainly target at balancing the distribution of the training data with respect to their tempo. In this paper, we investigate another approach for data augmentation, to account for the composition of the training data in terms of the percussive and non-percussive sound sources. Specifically, we propose to employ a blind drum separation model to segregate the drum and non-drum sounds from each training audio signal, filtering out training signals that are drumless, and then use the obtained drum and non-drum stems to augment the training data. We report experiments on four completely unseen test sets, validating the effectiveness of the proposed method, and accordingly the importance of drum sound composition in the training data for beat and downbeat tracking.

## Summary


## Quintessence


## üõ†Ô∏è Methods
- **Data:**  
- **Augmentations:**  
- **Features/Models:**  


## Takeaways for me


---
title: Live Music Models
authors: Lyria Team, Google DeepMind
year: "2025"
link:
  - https://arxiv.org/html/2508.04651v1
tags:
  - generation
relevance: high
---
## Abstract //todo shorten to summary!
We introduce a new class of generative models for music called _live music models_ that produce a continuous stream of music in real-time with synchronized user control. We release Magenta RealTime, an open-weights live music model that can be steered using text or audio prompts to control acoustic style. On automatic metrics of music quality, Magenta RealTime outperforms other open-weights music generation models, despite using fewer parameters and offering first-of-its-kind live generation capabilities. We also release Lyria RealTime, an API-based model with extended controls, offering access to our most powerful model with wide prompt coverage. These models demonstrate a new paradigm for AI-assisted music creation that emphasizes human-in-the-loop interaction for live music performance.

## Summary


## Quintessence


## üõ†Ô∏è Methods
- **Data:**  
- **Augmentations:**  
- **Features/Models:**  


## Takeaways for me


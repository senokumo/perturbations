---
title: "Feature separation of music across diverse dataset: a comparative perspective"
authors: Sakthidevi Shunmugalingam Parvathi, Divya Chandrasekar
year: "2025"
link:
  - https://www.researchgate.net/publication/396364696_Feature_separation_of_music_across_diverse_dataset_a_comparative_perspective
tags:
  - mir
relevance: mid
---
## Abstract //todo shorten to summary!
In music, feature separation is the process of separating distinguishable auditory characteristics, such as pitch, timbre, rhythm, and harmonic content, from a complicated, mixed signal. Virtual reality (VR), gaming, music transcription, karaoke systems, audio restoration, music information retrieval (MIR), music education, and audio forensics, are just a few of the areas where the topic has attracted a lot of attention. Feature extraction is crucial in music separation as it identifies and isolates sound elements, improving accuracy, and reducing noise. It simplifies raw audio into meaningful data for efficient processing and effective model learning. Without it, clean separation of audio components is very difficult. In this research, extracting features from mixed audio sources enables clean and accurate isolation of musical elements, enhancing quality, supporting precise evaluations, and boosting neural network performance across varied datasets including DSD100, MUSDB, and MUSDB18-HQ, which collectively afford rich musical content for making evaluations and benchmarks. Evaluation metrics, such as F1-score, precision, and recall, are utilized to demonstrate the performance data of the extracted features. The MUSDB18-HQ dataset yielded an overall increase of 17.86% in the F1-score metrics with significant increases in drums (+25.05%) and vocals (+20.04%), showing that the dataset was highly effective for feature separation.

## Summary


## Quintessence


## üõ†Ô∏è Methods
- **Data:**  
- **Augmentations:**  
- **Features/Models:**  


## Takeaways for me

